\documentclass{article}

\title{Distributed sorting with Apache Arrow Flight}
\author{Chengxin Ma}
\date{\today}

\usepackage{hyperref}
\usepackage{todonotes}

\begin{document}

\maketitle

\section{Introduction}
This report includes the design of a distributed sorting application which utilizes Apache Arrow Flight for communication.
The experiments demonstrates the performance of the application.

\section{Design}
\subsection{Test data}
The final goal of designing this application is to integrate it into a genomic data process pipeline, where data in the SAM format
\footnote{\url{https://en.wikipedia.org/wiki/SAM_(file_format)\#Format}} is sorted.

From the perspective of sorting, the most interesting fields are \texttt{RNAME} (the name of the references sequence) and \texttt{POS} (position).
They together determine the order in which records are sorted.

Thus, to simplify the prototyping work, we design a data structure with three fields: \texttt{GROUP}, \texttt{SEQ}, and \texttt{DATA}.
Each record belongs to a group and has a sequence number in that group.
Its data is placed in the \texttt{DATA} field.

Here is an example input file: \href{https://github.com/MaChengxin/playground/blob/master/arrow/flight/my_flight/data/nums_on_node_0.txt}{\textit{Input records on Node 0}},
and here is an example file containing expected sorted records: \href{https://github.com/MaChengxin/playground/blob/master/arrow/flight/my_flight/data/expected_nums_on_node_0.txt}{\textit{Expected sorted records on Node 0}}.
\footnote{The files are misnamed. It should be \textit{records} instead of \textit{nums}.}
Note that we do not necessarily need to write the output into files.

\subsection{Functional decomposition}

The following functional components must be implemented to complete the application.
\begin{itemize}
    \item sorter
    \item sender
    \item receiver
    \item merger
    \item storage (maybe optional)
\end{itemize}

The \textit{sorter} is responsible for sorting the input data in our desired order: records with smaller Group IDs are placed before those with large Group IDs.
If the Group IDs of two records are the same, the secondary criteria is the sequence number.

The \textit{sender} and \textit{receiver} are responsible for sending (sorted) data to destination nodes and receiving data from source node respectively.

The responsibility of the \textit{merger} is to merge the sorted data to a complete and sorted set of data.

\textit{Storage} is needed when we want to temporarily store the data before further processing.

\section{Implementation}
There are a few dependencies among the functional components.
The \textit{sorter} and the \textit{sender} has a clear dependency: \textit{sender} must wait until \textit{sorter} has sorted the input, or partitioned the inputs to groups with known destination.
The \textit{merger} must wait until the \textit{receiver} has got all the data.
The \textit{storage} functional component must be ready before the \textit{receiver} starts to work, otherwise \textit{receiver} would have nowhere to put the data for further process.
Thus, the current implementation runs three processes on each node: \textit{plasma-store-server}
\footnote{Instead of writing data to disk, we use \textit{Plasma Object Store} as the means of storage.}, 
\textit{receive-and-merge}, and \textit{sort-and-send}.
\footnote{These processes have to be started in the order they were introduced above.}

\subsection{Test run}
To see how the application runs, a test run has been performed.
4 nodes on Cartesius (\texttt{tcn337, tcn338, tcn339, tcn340}, we name them from Node 0 to 3 hereafter) were allocated for this test run.
The data for the test run contains records of 40 groups (from \texttt{GROUP0} t0 \texttt{GROUP39}), each having 500,000 records (i.e. the total number of records is 20 million.)
Each node has 5 million records in random order before the application runs, and we expected that after when the application finishes,
Node 0 stores records from \texttt{GROUP0} to \texttt{GROUP9},
Node 1 stores records from \texttt{GROUP10} to \texttt{GROUP19},
Node 2 stores records from \texttt{GROUP20} to \texttt{GROUP29},
Node 3 stores records from \texttt{GROUP30} to \texttt{GROUP39}, in the ascending order.

The size of the input and output files on each node is around 130 MB.

The test run was started one by one manually, in the order of from Node 0 to 3.
(Interval: about 1 second.)


\section{Experiments}

\todo[inline]{Experiments should be conducted after the problems in the implementation part has been finished.}

The goal of the experiments is to determine:
\begin{itemize}
    \item Does the performance become better if more nodes are used?
    \item How does the application behave when the volume of data increase?
    \item Where is the bottleneck of performance?
\end{itemize}

\subsection{Input size fixed, changing the number of nodes in use}

\subsection{Number of nodes fixed, changing the input size}

\section{Next steps}

\appendix
\section{Known issues}
\subsection{Building the project}

On macOS, the \texttt{grpc} library installed via \texttt{Homebrew} (as a dependency of \texttt{apache-arrow}) seems to be problematic.
The Flight server would incur a segmentation fault due to the current version (stable 1.26.0) of \texttt{grpc}.

We can make use of the existing build system of arrow to build \texttt{grpc} from source.
(The build system is capable of building any missing dependency from source.)
This also saves us from building missing dependencies manually on Cartesius.

\end{document}
