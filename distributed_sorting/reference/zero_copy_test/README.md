### Rationale of doing this test

Currently there is no ready-to-use API in Arrow to sort Record Batch.
As a workaround, we can:

* convert Record Batch to pandas DataFrame
* sort the pandas DataFrame
* convert back to Record Batch

The cost of conversion between Record Batch and DataFrame depends on the data type.
[Here](https://arrow.apache.org/docs/python/pandas.html#memory-usage-and-zero-copy) is a detailed explanation.

We want to see if we can make use of the zero-copy feature to help us make sorting faster.

We've tested the mechanism with two input data sets, generated by the `gen_*.py` scripts.

### Result of sorting 32 million records:

If the Record Batch contains only integers, there is no cost in conversion.
Sorting took 25 seconds.
(see `process_32m_ints.log`)

If the Record Batch contains integers and strings, conversion from Record Batch to DataFrame took 16 seconds,
sorting took 48 seconds, and converting from DataFrame to Record Batch took 17 seconds.
(see `process_32m_fake_SAM.log`)

### How to accelerate sorting input containing heterogeneous types?

**Untested yet, just an idea:**

Still, we start with a Record Batch.

* Step 1: get the columns relevant to sorting (expectation: zero-cost operation, if the columns are all numbers)
* Step 2: concatenate the columns as a DataFrame (expectation: low cost)
* Step 3: sort the DataFrame, retrieve [the index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.index.html) of the sorted DataFrame
* Step 4: build a new Record Batch based on the old one and the index from the previous step

Expectation:

* Step 1 + Step 2 faster than converting whole Record Batch to pandas DataFrame
* Step 3 faster than sorting the whole DataFrame
* Step 4 about the same as converting whole DataFrame to whole Record Batch
